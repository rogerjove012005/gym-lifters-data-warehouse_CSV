{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üìä ETL con PySpark\n",
        "\n",
        "Proceso ETL con PySpark para procesamiento distribuido de datos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.window import Window\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Crear SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"GymLiftersETL\") \\\n",
        "    .config(\"spark.sql.warehouse.dir\", \"warehouse\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "spark.sparkContext.setLogLevel(\"WARN\")\n",
        "print(f\"‚úÖ SparkSession creada - Version: {spark.version}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extracci√≥n - Cargar Dataset\n",
        "\n",
        "Cargar el dataset limpio generado con Pandas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cargar dataset limpio (buscar la versi√≥n m√°s reciente)\n",
        "import glob\n",
        "\n",
        "data_path = None\n",
        "\n",
        "# Buscar archivos con patr√≥n gym_lifters_clean_*.csv o gym_lifters_clean.csv\n",
        "pattern1 = \"../data/gym_lifters_clean_*.csv\"\n",
        "pattern2 = \"data/gym_lifters_clean_*.csv\"\n",
        "files1 = glob.glob(pattern1)\n",
        "files2 = glob.glob(pattern2)\n",
        "all_files = files1 + files2\n",
        "\n",
        "if all_files:\n",
        "    # Ordenar por fecha de modificaci√≥n y tomar el m√°s reciente\n",
        "    all_files.sort(key=os.path.getmtime, reverse=True)\n",
        "    data_path = all_files[0]\n",
        "    print(f\"üìÇ Archivo encontrado: {data_path}\")\n",
        "else:\n",
        "    # Buscar archivo sin numeraci√≥n (versi√≥n antigua)\n",
        "    if os.path.exists(\"../data/gym_lifters_clean.csv\"):\n",
        "        data_path = \"../data/gym_lifters_clean.csv\"\n",
        "    elif os.path.exists(\"data/gym_lifters_clean.csv\"):\n",
        "        data_path = \"data/gym_lifters_clean.csv\"\n",
        "    else:\n",
        "        raise FileNotFoundError(\"No se encuentra gym_lifters_clean.csv. Ejecuta primero la celda de limpieza en el notebook de Pandas\")\n",
        "\n",
        "df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(data_path)\n",
        "print(f\"‚úÖ Dataset cargado: {df.count():,} filas, {len(df.columns)} columnas\")\n",
        "print(f\"üìÅ Archivo: {os.path.basename(data_path)}\")\n",
        "df.show(5, truncate=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Transformaciones\n",
        "\n",
        "Aplicar filtrado, creaci√≥n de columnas derivadas y agregaciones.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Transformaci√≥n 1: Filtrado\n",
        "df_filtered = df.filter(\n",
        "    (col(\"total_kg\").isNotNull()) & \n",
        "    (col(\"total_kg\") > 0) &\n",
        "    (col(\"year\").isNotNull()) &\n",
        "    (col(\"year\") >= 2010) &\n",
        "    (col(\"year\") <= 2025)\n",
        ")\n",
        "print(f\"‚úÖ Filtrado: {df_filtered.count():,} registros\")\n",
        "df_filtered.select(\"name\", \"country\", \"year\", \"total_kg\").show(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Transformaci√≥n 2: Columnas derivadas\n",
        "df_with_metrics = df_filtered.withColumn(\n",
        "    \"efficiency_ratio\",\n",
        "    when(col(\"body_weight_kg\") > 0, col(\"total_kg\") / col(\"body_weight_kg\")).otherwise(None)\n",
        ").withColumn(\n",
        "    \"lift_difference\",\n",
        "    col(\"clean_and_jerk_kg\") - col(\"snatch_kg\")\n",
        ").withColumn(\n",
        "    \"performance_category\",\n",
        "    when(col(\"total_kg\") >= 350, \"Elite\")\n",
        "    .when(col(\"total_kg\") >= 300, \"Advanced\")\n",
        "    .when(col(\"total_kg\") >= 250, \"Intermediate\")\n",
        "    .otherwise(\"Beginner\")\n",
        ")\n",
        "print(\"‚úÖ Columnas derivadas creadas\")\n",
        "df_with_metrics.select(\"name\", \"total_kg\", \"efficiency_ratio\", \"performance_category\").show(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Transformaci√≥n 3: Agregaciones\n",
        "agg_by_country = df_with_metrics.groupBy(\"country\", \"category\") \\\n",
        "    .agg(\n",
        "        count(\"*\").alias(\"total_lifters\"),\n",
        "        avg(\"total_kg\").alias(\"avg_total_kg\"),\n",
        "        max(\"total_kg\").alias(\"max_total_kg\")\n",
        "    ) \\\n",
        "    .orderBy(desc(\"avg_total_kg\"))\n",
        "print(\"‚úÖ Agregaciones calculadas\")\n",
        "agg_by_country.show(10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ETL Completo - Modelo Dimensional\n",
        "\n",
        "Crear tablas de dimensiones y tabla de hechos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear dim_athlete\n",
        "print(\"üî® Creando dim_athlete...\")\n",
        "dim_athlete = df_with_metrics.select(\"athlete_id\", \"name\", \"gender\", \"age\", \"country\") \\\n",
        "    .distinct().filter(col(\"name\").isNotNull() & (col(\"name\") != \"\"))\n",
        "\n",
        "dim_athlete = dim_athlete.withColumn(\n",
        "    \"athlete_id_clean\",\n",
        "    when((col(\"athlete_id\").isNull()) | (col(\"athlete_id\") == \"\"), None).otherwise(col(\"athlete_id\"))\n",
        ").withColumn(\n",
        "    \"id_athlete\",\n",
        "    row_number().over(Window.orderBy(\"athlete_id_clean\", \"name\", \"country\"))\n",
        ").withColumn(\n",
        "    \"final_athlete_id\",\n",
        "    coalesce(col(\"athlete_id_clean\"), concat(lit(\"ath_\"), col(\"id_athlete\")))\n",
        ").select(\n",
        "    \"id_athlete\",\n",
        "    col(\"final_athlete_id\").alias(\"athlete_id\"),\n",
        "    \"name\", \"gender\", \"age\", \"country\"\n",
        ").distinct()\n",
        "\n",
        "print(f\"‚úÖ dim_athlete: {dim_athlete.count():,} atletas √∫nicos\")\n",
        "dim_athlete.show(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear dim_competition\n",
        "print(\"\\nüî® Creando dim_competition...\")\n",
        "dim_competition = df_with_metrics.select(\"competition\", \"year\", \"category\") \\\n",
        "    .distinct().filter(col(\"competition\").isNotNull() & col(\"year\").isNotNull())\n",
        "\n",
        "dim_competition = dim_competition.withColumn(\n",
        "    \"id_competition\",\n",
        "    row_number().over(Window.orderBy(\"year\", \"competition\", \"category\"))\n",
        ").select(\"id_competition\", \"competition\", \"year\", \"category\")\n",
        "\n",
        "print(f\"‚úÖ dim_competition: {dim_competition.count():,} competencias √∫nicas\")\n",
        "dim_competition.show(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear dim_team\n",
        "print(\"\\nüî® Creando dim_team...\")\n",
        "dim_team = df_with_metrics.select(\"team\", \"coach\") \\\n",
        "    .distinct().filter(col(\"team\").isNotNull())\n",
        "\n",
        "dim_team = dim_team.withColumn(\n",
        "    \"id_team\",\n",
        "    row_number().over(Window.orderBy(\"team\", \"coach\"))\n",
        ").select(\"id_team\", \"team\", \"coach\")\n",
        "\n",
        "print(f\"‚úÖ dim_team: {dim_team.count():,} equipos √∫nicos\")\n",
        "dim_team.show(5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tabla de Hechos\n",
        "\n",
        "Crear fact_lifting relacionando dimensiones con m√©tricas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear fact_lifting\n",
        "print(\"\\nüî® Creando fact_lifting...\")\n",
        "fact_base = df_with_metrics.select(\n",
        "    \"athlete_id\", \"name\", \"country\", \"competition\", \"year\", \"category\",\n",
        "    \"team\", \"coach\", \"snatch_kg\", \"clean_and_jerk_kg\", \"total_kg\",\n",
        "    \"body_weight_kg\", \"event_rank\", \"medal\", \"record_status\", \"lifting_style\",\n",
        "    \"efficiency_ratio\", \"lift_difference\", \"performance_category\"\n",
        ")\n",
        "\n",
        "# Join con dim_athlete (usar name y country como clave principal)\n",
        "fact_with_athlete = fact_base.join(\n",
        "    dim_athlete,\n",
        "    (fact_base.name == dim_athlete.name) & (fact_base.country == dim_athlete.country),\n",
        "    \"inner\"\n",
        ").select(\n",
        "    fact_base[\"competition\"], fact_base[\"year\"], fact_base[\"category\"],\n",
        "    fact_base[\"team\"], fact_base[\"coach\"], fact_base[\"snatch_kg\"],\n",
        "    fact_base[\"clean_and_jerk_kg\"], fact_base[\"total_kg\"], fact_base[\"body_weight_kg\"],\n",
        "    fact_base[\"event_rank\"], fact_base[\"medal\"], fact_base[\"record_status\"],\n",
        "    fact_base[\"lifting_style\"], fact_base[\"efficiency_ratio\"],\n",
        "    fact_base[\"lift_difference\"], fact_base[\"performance_category\"],\n",
        "    dim_athlete[\"id_athlete\"]\n",
        ")\n",
        "\n",
        "# Join con dim_competition\n",
        "fact_with_competition = fact_with_athlete.join(\n",
        "    dim_competition,\n",
        "    (fact_with_athlete.competition == dim_competition.competition) &\n",
        "    (fact_with_athlete.year == dim_competition.year) &\n",
        "    (coalesce(fact_with_athlete.category, lit(\"\")) == coalesce(dim_competition.category, lit(\"\"))),\n",
        "    \"inner\"\n",
        ").select(\n",
        "    fact_with_athlete[\"id_athlete\"], fact_with_athlete[\"team\"], fact_with_athlete[\"coach\"],\n",
        "    fact_with_athlete[\"snatch_kg\"], fact_with_athlete[\"clean_and_jerk_kg\"],\n",
        "    fact_with_athlete[\"total_kg\"], fact_with_athlete[\"body_weight_kg\"],\n",
        "    fact_with_athlete[\"event_rank\"], fact_with_athlete[\"medal\"],\n",
        "    fact_with_athlete[\"record_status\"], fact_with_athlete[\"lifting_style\"],\n",
        "    fact_with_athlete[\"efficiency_ratio\"], fact_with_athlete[\"lift_difference\"],\n",
        "    fact_with_athlete[\"performance_category\"], dim_competition[\"id_competition\"]\n",
        ")\n",
        "\n",
        "# Join con dim_team\n",
        "fact_lifting = fact_with_competition.join(\n",
        "    dim_team,\n",
        "    (fact_with_competition.team == dim_team.team) &\n",
        "    (coalesce(fact_with_competition.coach, lit(\"\")) == coalesce(dim_team.coach, lit(\"\"))),\n",
        "    \"inner\"\n",
        ").select(\n",
        "    col(\"id_athlete\"), col(\"id_competition\"), col(\"id_team\"),\n",
        "    \"snatch_kg\", \"clean_and_jerk_kg\", \"total_kg\", \"body_weight_kg\",\n",
        "    \"event_rank\", \"medal\", \"record_status\", \"lifting_style\",\n",
        "    \"efficiency_ratio\", \"lift_difference\", \"performance_category\"\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ fact_lifting: {fact_lifting.count():,} registros\")\n",
        "fact_lifting.show(5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Carga - Guardar en SQLite\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Carga - Guardar en SQLite\n",
        "\n",
        "# Preparar y cargar en SQLite\n",
        "if os.path.exists(\"../warehouse\"):\n",
        "    os.makedirs(\"../warehouse\", exist_ok=True)\n",
        "    db_path = \"../warehouse/warehouse_pyspark.db\"\n",
        "else:\n",
        "    os.makedirs(\"warehouse\", exist_ok=True)\n",
        "    db_path = \"warehouse/warehouse_pyspark.db\"\n",
        "\n",
        "if os.path.exists(db_path):\n",
        "    os.remove(db_path)\n",
        "\n",
        "conn = sqlite3.connect(db_path)\n",
        "\n",
        "# Convertir a Pandas y cargar\n",
        "tables = [\n",
        "    (\"dim_athlete\", dim_athlete),\n",
        "    (\"dim_competition\", dim_competition),\n",
        "    (\"dim_team\", dim_team),\n",
        "    (\"fact_lifting\", fact_lifting)\n",
        "]\n",
        "\n",
        "print(\"üìä Cargando tablas en SQLite...\")\n",
        "for name, df_spark in tables:\n",
        "    df_pd = df_spark.toPandas()\n",
        "    df_pd.to_sql(name, conn, if_exists=\"replace\", index=False)\n",
        "    print(f\"   ‚úÖ {name}: {len(df_pd):,} registros\")\n",
        "\n",
        "conn.close()\n",
        "print(f\"\\n‚úÖ ETL completado! Base de datos: {db_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Verificaci√≥n\n",
        "\n",
        "Verificar datos cargados en SQLite.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verificaci√≥n final\n",
        "conn = sqlite3.connect(db_path)\n",
        "tables = [\"dim_athlete\", \"dim_competition\", \"dim_team\", \"fact_lifting\"]\n",
        "\n",
        "print(\"üìä Resumen de tablas:\")\n",
        "for table in tables:\n",
        "    count = pd.read_sql_query(f\"SELECT COUNT(*) as count FROM {table}\", conn)['count'].iloc[0]\n",
        "    print(f\"   ‚úÖ {table}: {count:,} registros\")\n",
        "\n",
        "print(\"\\nüìù Muestras:\")\n",
        "for table in tables:\n",
        "    display(pd.read_sql_query(f\"SELECT * FROM {table} LIMIT 3\", conn))\n",
        "\n",
        "conn.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Consultas de Ejemplo\n",
        "\n",
        "Ejemplos de consultas SQL sobre el data warehouse.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Consultas de ejemplo\n",
        "conn = sqlite3.connect(db_path)\n",
        "\n",
        "print(\"üìä Consulta 1: Top 10 atletas por total_kg\")\n",
        "query1 = \"\"\"\n",
        "SELECT a.name, a.country, a.gender,\n",
        "    COUNT(f.id_athlete) as total_competitions,\n",
        "    AVG(f.total_kg) as avg_total_kg,\n",
        "    MAX(f.total_kg) as max_total_kg\n",
        "FROM fact_lifting f\n",
        "JOIN dim_athlete a ON f.id_athlete = a.id_athlete\n",
        "GROUP BY a.id_athlete, a.name, a.country, a.gender\n",
        "ORDER BY max_total_kg DESC LIMIT 10\n",
        "\"\"\"\n",
        "display(pd.read_sql_query(query1, conn))\n",
        "\n",
        "print(\"\\nüìä Consulta 2: Promedio por pa√≠s\")\n",
        "query2 = \"\"\"\n",
        "SELECT a.country,\n",
        "    COUNT(DISTINCT a.id_athlete) as num_athletes,\n",
        "    AVG(f.total_kg) as avg_total_kg,\n",
        "    MAX(f.total_kg) as max_total_kg\n",
        "FROM fact_lifting f\n",
        "JOIN dim_athlete a ON f.id_athlete = a.id_athlete\n",
        "GROUP BY a.country\n",
        "ORDER BY avg_total_kg DESC LIMIT 10\n",
        "\"\"\"\n",
        "display(pd.read_sql_query(query2, conn))\n",
        "\n",
        "print(\"\\nüìä Consulta 3: Competencias con m√°s participantes\")\n",
        "query3 = \"\"\"\n",
        "SELECT c.competition, c.year, c.category,\n",
        "    COUNT(f.id_athlete) as num_participants,\n",
        "    AVG(f.total_kg) as avg_total_kg\n",
        "FROM fact_lifting f\n",
        "JOIN dim_competition c ON f.id_competition = c.id_competition\n",
        "GROUP BY c.id_competition, c.competition, c.year, c.category\n",
        "ORDER BY num_participants DESC LIMIT 10\n",
        "\"\"\"\n",
        "display(pd.read_sql_query(query3, conn))\n",
        "\n",
        "conn.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cerrar SparkSession\n",
        "spark.stop()\n",
        "print(\"‚úÖ SparkSession cerrada\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
